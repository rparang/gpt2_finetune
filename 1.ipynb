{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15928746-c88c-412f-a6b8-4303acbea481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d2dcd51-8f9e-4a95-801a-5a25b91b7de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['version', 'data']\n"
     ]
    }
   ],
   "source": [
    "with open('questions.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        print(\"Keys:\", list(data.keys()))\n",
    "\n",
    "    data = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f130c1-1468-4ceb-b760-3aa852e99311",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[400]['paragraphs'][1]['qas'][1]['answers'][0].get('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5ddb0d04-2921-4066-96f7-d75160618229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'the Church holds that Mary was also sinless personally, \"free from all sin, original or personal',\n",
       "  'answer_start': 160}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[400]['paragraphs'][1]['qas'][1].get('answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2e96f7e0-2473-48f5-a987-a2f3944481e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gooz = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a10cc779-8f4b-48d7-8b61-7db183a6b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i in range(len(data)):\n",
    "    paragraphs = data[i]['paragraphs']\n",
    "    for j in range(len(paragraphs)):\n",
    "        qas = paragraphs[j]['qas']\n",
    "        for k in range(len(qas)):\n",
    "            question = qas[k]['question']\n",
    "            answer = qas[k].get('answers')\n",
    "            if len(answer) > 0:\n",
    "                # text = answer\n",
    "                completion = answer[0].get('text')\n",
    "            if question != '':\n",
    "                prompt = question\n",
    "            gooz.append({\"prompt\": question, \"completion\": completion})\n",
    "            # text = \"Q: \" + prompt + \" A: \" + completion\n",
    "            # gooz.append(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a2d073-563b-464c-9216-a11c36ce9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gooz[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "84aa430e-46f0-461e-a8bc-90826a0f71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(gooz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8c155823-0ee4-44eb-aa10-70cf1221fe30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['completion'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bd60528a-0b35-44b3-a73c-58fdeea4bea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary successfully saved to qa_dataset.json1\n"
     ]
    }
   ],
   "source": [
    "file_path = \"qa_dataset.json1\"\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(gooz, json_file, indent=4)\n",
    "    print(f\"Dictionary successfully saved to {file_path}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error saving file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9447e285-f4f9-477c-9ecf-5d6ab05a2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"qa_dataset.json\", \"r\") as f_in, open(\"qa_dataset.jsonl\", \"w\") as f_out:\n",
    "    data = json.load(f_in)  # Loads the list of objects\n",
    "    for item in data:\n",
    "        json.dump(item, f_out)\n",
    "        f_out.write('\\n')  # Write each object on its own line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "91be84ea-7e12-49c4-9147-6dd9aea17856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoder = tiktoken.get_encoding('gpt2')\n",
    "encoder.encode(\"<BOS>\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8d4a5cc2-71a3-453b-a617-3676620414e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496, 616, 1545]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# tokenizer.get_vocab()\n",
    "tokenizer.encode(\"Hello my friend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "af6eb671-5a10-4540-82b2-26eaa815e0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens_dict = {\n",
    "    \"bos_token\": \"<BOS>\",\n",
    "    \"eos_token\": \"<EOS>\",\n",
    "    \"sep_token\": \"<SEP>\",\n",
    "    \"pad_token\": \"<PAD>\"\n",
    "}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "9b1114d0-b75d-4913-9c41-204aa8fa0910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<When did Beyonce start becoming popular?<in the late 1990s<'"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(tokenizer.get_vocab())\n",
    "# tokenizer.get_vocab()[\"<PAD>\"]\n",
    "# tokenizer.encode(\"<PAD>\")\n",
    "tokenizer.decode([27, 2215, 750, 37361, 344, 923, 5033, 2968, 30, 27, 259, 262, 2739, 6303, 82, 27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "ec42b735-c972-484f-bbfd-e99cc0e74cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "class QADataLoader:\n",
    "    def __init__(self, filepath, max_length=512, shuffle=True):\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        self.max_length = max_length\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.tokenizer.add_special_tokens({\n",
    "            \"bos_token\": \"<BOS>\",\n",
    "            \"eos_token\": \"<EOS>\",\n",
    "            \"sep_token\": \"<SEP>\",\n",
    "            \"pad_token\": \"<PAD>\"\n",
    "        })\n",
    "\n",
    "        self.special_tokens = {\n",
    "            \"<BOS>\": self.tokenizer.encode(\"<BOS>\")[0],\n",
    "            \"<SEP>\": self.tokenizer.encode(\"<SEP>\")[0],\n",
    "            \"<EOS>\": self.tokenizer.encode(\"<EOS>\")[0],\n",
    "            \"<PAD>\": self.tokenizer.encode(\"<PAD>\")[0]\n",
    "        }\n",
    "\n",
    "        self.samples = []\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                item = json.loads(line.strip())\n",
    "                q, a = item[\"prompt\"], item[\"completion\"]\n",
    "                tokens = self.encode_sample(q, a)\n",
    "                if len(tokens[\"input_ids\"]) <= self.max_length:\n",
    "                    self.samples.append(tokens)\n",
    "\n",
    "    def encode_sample(self, question, answer):\n",
    "        q_tokens = self.tokenizer.encode(question)\n",
    "        a_tokens = self.tokenizer.encode(answer)\n",
    "\n",
    "        input_ids = (\n",
    "            [self.special_tokens[\"<BOS>\"]] + \n",
    "            q_tokens + \n",
    "            [self.special_tokens[\"<SEP>\"]] +\n",
    "            a_tokens +\n",
    "            [self.special_tokens[\"<EOS>\"]]\n",
    "        )\n",
    "\n",
    "        label_ids = (\n",
    "            [-100] * (1 + len(q_tokens) + 1) + \n",
    "            a_tokens +\n",
    "            [self.special_tokens[\"<EOS>\"]]\n",
    "         )\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"label_ids\": label_ids}     \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        if self.shuffle:\n",
    "            batch = random.sample(self.samples, batch_size)\n",
    "        else:\n",
    "            batch = self.samples[:batch_size]\n",
    "        \n",
    "        max_len = max(len(sample[\"input_ids\"]) for sample in batch)\n",
    "        input_ids_batch = []\n",
    "        label_ids_batch = []\n",
    "        attention_mask_batch = []\n",
    "\n",
    "        for sample in batch:\n",
    "            pad_len = max_len - len(sample[\"input_ids\"])\n",
    "            input_ids = sample[\"input_ids\"] + [self.special_tokens[\"<PAD>\"]] * pad_len\n",
    "            label_ids = sample[\"label_ids\"] + [-100] * pad_len\n",
    "            attention_mask = [1] * len(sample[\"input_ids\"]) + [0] * pad_len\n",
    "\n",
    "            input_ids_batch.append(input_ids)\n",
    "            label_ids_batch.append(label_ids)\n",
    "            attention_mask_batch.append(attention_mask)\n",
    "            \n",
    "        return {\n",
    "            \"input_ids\": input_ids_batch, \n",
    "            \"label_ids\": label_ids_batch,\n",
    "            \"attention_mask\": attention_mask_batch\n",
    "        }     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "112b04cd-b5c4-4e81-bd60-91c5f192ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = QADataLoader(\"qa_small_dataset.jsonl\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "12474488-b360-413a-aff9-e72b6ff06b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader.samples) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "5546bc70-828d-4943-90a7-7760ea80107d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1, 21])"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = dataloader.get_batch(2)\n",
    "# print(batches['input_ids'][0])\n",
    "# print(batches['label_ids'][0])\n",
    "# tokenizer.decode(batches['inputs_ids'][0])\n",
    "\n",
    "# batches['input_ids'][0]\n",
    "tokenizer.decode(batches['input_ids'][0])\n",
    "\n",
    "batches['attention_mask']\n",
    "# batches\n",
    "# print(tokenizer.decode(batches[\"input_ids\"][3]))\n",
    "\n",
    "# tokenizer.decode(batches['label_ids'][0])\n",
    "# batches['label_ids'][0]\n",
    "# tokenizer.decode(-100)\n",
    "\n",
    "\n",
    "# for batch in batches:\n",
    "#     print(len(batch['input_ids']))\n",
    "#     print(len(batch['label_ids']))\n",
    "\n",
    "attention_mask = batches['attention_mask']\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "attention_mask[:, None, None, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "4468aba4-d97b-4a5c-83d7-837d578c812d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 21])"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bdffc257-764e-43fc-b3f8-b925402f2bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([9, 6, 7, 7, 7, 9, 6, 0, 1, 0, 6, 8, 6, 7, 6, 2, 0, 6, 3, 9],\n",
       " [9,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  9,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "gooz_ids = np.random.randint(0, 10, size=20).tolist()\n",
    "gooz_labels = gooz_ids[:10]\n",
    "gooz_labels = gooz_labels + [-100] * 10\n",
    "gooz_ids, gooz_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "6efbb7c9-088d-4ed5-a516-0d03b275367a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-6.2602e-01,         inf,         inf,         inf],\n",
       "          [ 1.2883e-01, -5.3285e-02,         inf,         inf],\n",
       "          [-4.2524e-01,  1.2064e-01, -5.7070e-01,         inf],\n",
       "          [ 1.7759e+00,  9.9432e-01,  4.1436e-04,  7.3606e-01]],\n",
       "\n",
       "         [[ 4.9656e-01,         inf,         inf,         inf],\n",
       "          [ 9.4131e-03, -4.7672e-02,         inf,         inf],\n",
       "          [ 2.0352e-01,  3.7636e-01,  1.4296e-01,         inf],\n",
       "          [-5.0593e-01, -5.2762e-01, -8.0086e-01, -1.4362e-02]]],\n",
       "\n",
       "\n",
       "        [[[-5.1723e-02,         inf,         inf,         inf],\n",
       "          [ 3.5109e-01, -2.1513e-01,         inf,         inf],\n",
       "          [ 1.0144e+00, -2.6050e-01,  4.5848e-01,         inf],\n",
       "          [ 2.3837e-01, -3.6955e-01, -3.2761e-01, -5.8813e-01]],\n",
       "\n",
       "         [[ 2.8595e-01,         inf,         inf,         inf],\n",
       "          [ 2.5033e-01, -1.2565e-01,         inf,         inf],\n",
       "          [-6.0656e-01,  1.5357e-01,  1.4696e-01,         inf],\n",
       "          [-8.0639e-01,  2.7095e-02, -2.6864e+00, -1.6657e-01]]]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "B, T, n_embd = 2, 4, 8\n",
    "n_head = 2\n",
    "\n",
    "bias = torch.tril(torch.ones(T, T)).view(1, 1, T, T)\n",
    "\n",
    "x = torch.randn(B, T, n_embd)\n",
    "\n",
    "c_attn = nn.Linear(n_embd, 3*n_embd)\n",
    "qkv = c_attn(x)\n",
    "q, k, v = qkv.split(n_embd, dim=2)\n",
    "\n",
    "k = k.view(B, T, n_head, n_embd // n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "q = q.view(B, T, n_head, n_embd // n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "v = v.view(B, T, n_head, n_embd // n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "q.shape\n",
    "\n",
    "att = q @ k.transpose(-2, -1)\n",
    "att.shape, bias.shape\n",
    "att = att.masked_fill(bias[:, :, :T, :T] == 0, float('inf'))\n",
    "bias[:, :, :T, :T]\n",
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "af3a88e9-6033-45a4-b206-ad3d1ed1dd09",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (21) must match the size of tensor b (16) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[702], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m attention_mask[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[0;32m----> 2\u001b[0m att \u001b[38;5;241m=\u001b[39m att\u001b[38;5;241m.\u001b[39mmasked_fill(attention_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      3\u001b[0m att\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (21) must match the size of tensor b (16) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "attention_mask = attention_mask[:, None, None, :]\n",
    "att = att.masked_fill(attention_mask == 0, float('inf'))\n",
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "6260dc24-953f-4bd5-856f-345e01eb11ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8019])"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "x1 = x[-1,-1, :]\n",
    "x1[:1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
